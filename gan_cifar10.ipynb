{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Configuration\n",
    "GPU_COUNT = 1\n",
    "WINDOWS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas\n",
    "!pip install -q seaborn\n",
    "!pip install -q matplotlib\n",
    "!pip install -q neptune-client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cifar10.PNG\" width=700>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks - CIFAR10\n",
    "> Can we create a strong generative model for CIFAR10 using the GAN architecture?\n",
    "\n",
    "## Background Research üìñ\n",
    "\n",
    "### Introduction üí°\n",
    "The ultimate goal of Deep Learning is to be able to create a function that can <strong>effectively</strong> model any form of data distribution. History has time and time again displayed the impressive success of discriminators, models that learn to divide the data distribution/map a high dimensional vector to one that is lower (Goodfellow et al., 2014). For instance, tasks such as Image Classification are one type of discriminative modelling, as the high dimensional images are mapped into low dimensional probabilities of labels.\n",
    "\n",
    "What about generative modelling? In generative modelling, the goal is instead given a data distribution to learn from, to produce or generate new examples that follow but this distribution but still prove to be unique. Thus, a high performing generative model should be able to create examples that are both plausible (in that one can recognize what the generated example is supposed to be of) and indistinguishable from real data examples (Brownlee, 2019). Generative models can be Unsupervised or Semi-Supervised, depending on the exact task that one is trying to tackle. \n",
    "\n",
    "There are different approaches to network architectures when it comes to trying to achieve Generative Models:\n",
    "<ul>\n",
    "\t<li>Generative Adversarial Networks (GAN) </li>\n",
    "\t<li>Diffusion Models</li>\n",
    "\t<li>Variational Auto Encoders (VAE)</li>\n",
    "</ul>\n",
    "\n",
    "<strong>GANs ‚öîÔ∏è</strong> <br />\n",
    "GANs are the main focus of this notebook. Proposed by Ian Goodfellow in 2014, it became one of the more popular types of Generative Models used. For instance, the commonly known website <a href=\"thispersondoesnotexist.com\">thispersondoesnotexist.com</a> uses the StyleGAN2 architecture (Karras et al., 2020). The idea for GANs is that there are two networks that work against each other in a game, where they try to one up each other. Thus, this leads to improvement in both networks. More details are discussed under \"What's inside a GAN? üîç\".\n",
    "\n",
    "<strong>Diffusion Models ‚ú®</strong><br /> \n",
    "These are the models that have been not only been successful, but widely popular as well. For instance, OpenAI Dall-E, Google Imagen, Stable Diffusion, Midjourney are models that fall under the category of Diffusion Models. (Muppalla and Hendryx, 2022). From a high level, it works like so:\n",
    "<ul>\n",
    "\t<li>Noise is added to original images</li>\n",
    "\t<li>Noise is procedurally added until image is all noise</li>\n",
    "\t<li>The model then learns to remove the noise</li>\n",
    "\t<li>Guidance can be added in the form of e.g. text-to-image, to provide direction of the generation process</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"images/diffusion1.jpg\" width=400/><br />\n",
    "*Noise is procedurally added to the image*\n",
    "\n",
    "<img src=\"images/diffusion2.jpg\" width=400/><br />\n",
    "*Model attempts to recreate the image. (Muppalla and Hendryx, 2022)*\n",
    "\n",
    "\n",
    "\n",
    "<strong>Variational Auto Encoders üé≤</strong><br />\n",
    "We first take a look at what Auto Encoders are. Essentially,\n",
    "\n",
    "Variational now induce randomness into these AutoEncoders.\n",
    "\n",
    "### What's inside a GAN? üîç\n",
    "Generator and Discriminatorto use the well understood and established classification model to train \n",
    "\n",
    "### Types of GANs üçê\n",
    "GAN\n",
    "Conditional GAN.\n",
    "\n",
    "One may argue that the Conditional GAN.\n",
    "\n",
    "### The difficulty with GANs üß©\n",
    "GANs are \n",
    " \n",
    "Mode collapse\n",
    "Stability - hyperparamter tuning is very important versus discriminator models where hyperparameters more often than not determine .\n",
    "\n",
    "### Loss Functions üèì\n",
    "Different Loss functions, main one being KL Divergence.\n",
    "Explain how KL Divergence works.\n",
    "There are papers claiming that novel loss functions improve stability.\n",
    "There are also papers https://arxiv.org/abs/1811.09567 that claim that loss functions don't really matter.\n",
    "This is an area of research I will attempt to explore in the notebook as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing the GAN\n",
    "### Objectives\n",
    "<ol>\n",
    "\t<li>Explore the CIFAR10 dataset</li>\n",
    "\t<li>Implement and evaluate to find the best performing model</li>\n",
    "\t<li>Analyse the final model</li>\n",
    "</ol>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "We define some utility functions below that will ease and help us with our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_data(data, loc):\n",
    "\tdatacopy = copy.deepcopy(data)\n",
    "\tarr = np.array(datacopy.loc[loc].drop('label'))\n",
    "\tlabel = datacopy.loc[loc]['label']\n",
    "\troot = int(len(arr) ** 0.5)\n",
    "\tarr.resize((root, root))\n",
    "\treturn label, arr\n",
    "\n",
    "def imshow(arr: list, label: list = None, figsize=None, shape = (32, 32, 3), is_int = None):\n",
    "\tif is_int == None:\n",
    "\t\tif type(arr[0]) == torch.Tensor:\n",
    "\t\t\tis_int = (arr[0].detach().cpu().numpy() > 1).sum() > 0\n",
    "\t\telse:\n",
    "\t\t\tis_int = (arr[0] > 1).sum() > 0\n",
    "\tif label == None:\n",
    "\t\tlabel = [''] * len(arr)\n",
    "\n",
    "\theight = int(len(arr) ** 0.5)\n",
    "\twidth = math.ceil(len(arr) / height)\n",
    "\n",
    "\tif figsize == None:\n",
    "\t\tfig = plt.figure()\n",
    "\telse:\n",
    "\t\tfig = plt.figure(figsize=figsize)\n",
    "\tfor i in range(height):\n",
    "\t\tfor j in range(width):\n",
    "\t\t\tax = fig.add_subplot(height, width, i * height + j + 1)\n",
    "\t\t\tax.grid(False)\n",
    "\t\t\tax.set_xticks([])\n",
    "\t\t\tax.set_yticks([])\n",
    "\t\t\tshow = arr[i * height + j]\n",
    "\t\t\tif type(arr[i * height + j]) != torch.Tensor:\n",
    "\t\t\t\tshow = torch.Tensor(show)\n",
    "\t\t\t\t# ax.imshow((arr[i * height + j].squeeze(0).cpu().permute(1, 2, 0) / 255).type(torch.uint8 if is_int else float))\n",
    "\t\t\t# if (show.shape[0] == 1):\n",
    "\t\t\t# \tax.imshow((show.squeeze(0).cpu()).type(torch.uint8 if is_int else torch.float), cmap='gray')\n",
    "\t\t\t# else:\n",
    "\t\t\tif len(show.squeeze(0).cpu().shape) == 2:\n",
    "\t\t\t\tax.imshow((show.squeeze(0).detach().cpu()).type(torch.uint8 if is_int else torch.float), cmap='gray')\n",
    "\t\t\telse:\n",
    "\t\t\t\tax.imshow((show.squeeze(0).detach().cpu().permute(1,2,0)).type(torch.uint8 if is_int else torch.float))\n",
    "\t\t\tax.set_title(label[i * height + j])\n",
    "\n",
    "def df_to_tensor(df, shape = (28, 28)):\n",
    "\treturn torch.tensor(df.values.reshape((-1, *shape)), dtype=torch.float32)\n",
    "\n",
    "def preprocess(df):\n",
    "\treturn df.copy() / 255"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d19efe0496419facc97fd7ea20d5d3a0b9c1bdc9473c8f87e1305d92cacb204"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
